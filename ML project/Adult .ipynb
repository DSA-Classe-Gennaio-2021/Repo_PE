{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['education','income'])['income'].count().unstack().plot(kind='bar')\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_education = df.groupby(['education','income'])['income'].count().unstack()\n",
    "money_education['ratio'] = money_education['>50K']/money_education.sum(axis=1)\n",
    "money_education.sort_values('ratio',ascending=False).ratio.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['workclass','marital.status','occupation','relationship','race','sex']:\n",
    "    df.groupby([i,'income'])['income'].count().unstack().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df.copy()\n",
    "clean_df.replace('?',np.nan,inplace=True)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(clean_df.isnull(),cmap='binary_r',cbar=False);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some columns with null values, plus, as expected, workclass and occupation show the same null values pattern. Let's see the percentage of these values versus the overall data and evaluate whether they can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.occupation.isnull().sum()/clean_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.workclass.isnull().sum()/clean_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['native.country'].isna().sum()/clean_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.dropna(axis=1,inplace=True)\n",
    "clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.drop('fnlwgt',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "clean_df[clean_df.select_dtypes('int64').columns] = standard_scaler.fit_transform(clean_df[clean_df.select_dtypes('int64').columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Example mean after standardization: {:.2f}'.format(clean_df.iloc[:,0].mean()))\n",
    "print('Example std after standardization: {:.2f}'.format(clean_df.iloc[:,0].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['income'] = clean_df.income.str.replace('<=50K','0').str.replace('>50K','1').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(clean_df.corr(),cmap='CMRmap');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(clean_df[['age','capital.loss','capital.gain','income']],figsize=(10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between numerical features seems to be weak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.drop('education',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.get_dummies(clean_df)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df_new.corr(),cmap='RdBu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.drop('income',axis=1).values\n",
    "y = df_new.income.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,shuffle=True,test_size=0.2,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'algorithm':['auto','brute','kd_tree'],\n",
    "          'weights' : ['uniform','distance'],\n",
    "          'n_neighbors' : [i for i in range(1,11)]}\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "model = GridSearchCV(estimator = knc, param_grid = params, cv=10, n_jobs=-1, scoring='balanced_accuracy')\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best_params: ',model.best_params_)\n",
    "print('best_score: ',model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "fpr, tpr, tresholds = roc_curve(y_test,preds_proba[:,1])\n",
    "auc_score = roc_auc_score(y_test,preds_proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0,1],'k--')\n",
    "plt.plot(fpr,tpr,'r')\n",
    "plt.title('KNeighborsClassifier ROC with GridSearchCV')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.annotate('AUC = {:.2f}'.format(auc_score),xy=(0.6,0.2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = []\n",
    "acc_train = []\n",
    "for k in (range(1,17)):\n",
    "    knn=KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_knn_test = knn.predict(X_test)\n",
    "    pred_knn_train = knn.predict(X_train)\n",
    "    acc_test.append(balanced_accuracy_score(y_test,pred_knn_test))\n",
    "    acc_train.append(balanced_accuracy_score(y_train,pred_knn_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,17), acc_test, 'p-', label='test')\n",
    "plt.plot(range(1,17), acc_train, 'rp-', label='train')\n",
    "plt.xticks(range(1,17));\n",
    "plt.legend()\n",
    "plt.xlabel('k_neighbors')\n",
    "plt.ylabel('Balanced accuracy')\n",
    "plt.title('Train vs Test balanced accuracy',{'fontsize':15});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc = KNeighborsClassifier(n_neighbors=15)\n",
    "knc.fit(X_train,y_train)\n",
    "preds_k_15 = knc.predict(X_test)\n",
    "preds_prob_k_15 = knc.predict_proba(X_test)[:,1]\n",
    "fpr_k_15, tpr_k_15, tresholds_k_15 = roc_curve(y_test,preds_prob_k_15)\n",
    "auc_score_k_15 = roc_auc_score(y_test,preds_prob_k_15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0,1],'k--')\n",
    "plt.plot(fpr_k_15,tpr_k_15,'r')\n",
    "plt.title('KNeighborsClassifier ROC with n = 15')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.annotate('AUC = {:.2f}'.format(auc_score_k_15),xy=(0.6,0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "params = {'criterion':['gini','entropy'],\n",
    "          'max_depth':[1,2,3,4,5],\n",
    "          'min_samples_split': [2,3,4,5,6],\n",
    "          'min_samples_leaf':[1,2,3,4,5]}\n",
    "\n",
    "tree_model = GridSearchCV(estimator=dt, param_grid=params, cv = 10, n_jobs=-1,scoring='balanced_accuracy')\n",
    "tree_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best_params:',tree_model.best_params_)\n",
    "print('best_score: ',tree_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_preds = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_preds_prob = tree_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Balanced accuracy: {:.2f}'.format(balanced_accuracy_score(y_test,tree_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tree, tpr_tree, tresholds_tree = roc_curve(y_test,tree_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score_tree = roc_auc_score(y_test,tree_preds_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0,1],'k--')\n",
    "plt.plot(fpr_tree,tpr_tree,'g')\n",
    "plt.title('DecisionTreeClassifier ROC')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.annotate('AUC = {:.2f}'.format(auc_score_tree),xy=(0.6,0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.corr()['income'][(df_new.corr()['income']>0.3) | (df_new.corr()['income']<-0.3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above the fetures that are linearlly correlated the most with income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_logr = df_new.drop('income',axis=1).values\n",
    "y_logr = df_new['income']\n",
    "\n",
    "X_train_lr, X_test_lr, y_train_lr, y_test_lr = train_test_split(X_logr,y_logr,test_size=0.2,random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = LogisticRegression()\n",
    "logr.fit(X_train_lr, y_train_lr)\n",
    "preds_logr = logr.predict(X_test_lr)\n",
    "preds_prob_logr =logr.predict_proba(X_test_lr)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_log, tpr_log, tresholds_log = roc_curve(y_test_lr,preds_prob_logr)\n",
    "auc_score_log = roc_auc_score(y_test_lr,preds_prob_logr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0,1],'k--')\n",
    "plt.plot(fpr_log,tpr_log,'c')\n",
    "plt.title('LogisticRegression ROC')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.annotate('AUC = {:.2f}'.format(auc_score_log),xy=(0.6,0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble method: Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_preds=rf.predict(X_test)\n",
    "rf_pred_probs = rf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(y_test,rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf, tpr_rf, tresholds_rf = roc_curve(y_test,rf_pred_probs)\n",
    "auc_score_rf = roc_auc_score(y_test,rf_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0,1],'k--')\n",
    "plt.plot(fpr_rf,tpr_rf,'y')\n",
    "plt.title('RandomForest ROC')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.annotate('AUC = {:.2f}'.format(auc_score_rf),xy=(0.6,0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features importances in RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf.feature_importances_, index=df_new.drop('income',axis=1).columns).sort_values(by=0).plot(kind='barh')\n",
    "plt.legend(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing ROC - AUC of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot([0,1],'k--')\n",
    "plt.plot(fpr_log,tpr_log,'c',label='LogReg')\n",
    "plt.plot(fpr_tree,tpr_tree,'g', label='DT')\n",
    "plt.plot(fpr_k_15,tpr_k_15,'r', label='KNC')\n",
    "plt.plot(fpr_rf,tpr_rf,'y',label='RF')\n",
    "plt.title('ROC - AUC')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like LogisticRegression performed better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
